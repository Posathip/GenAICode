{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h_unep3tSZd"
      },
      "outputs": [],
      "source": [
        "# !pip install -U \"transformers[torch]\" \"datasets>=2.16.0\" \"accelerate>=0.26.0\" \\\n",
        "# \"evaluate\" \"pandas>=2.0.0\" \"matplotlib\" \"scikit-learn\" \"umap-learn\" \"huggingface_hub\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bVaSuhzu_va"
      },
      "outputs": [],
      "source": [
        "\n",
        "# hide_output\n",
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset(\"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPi0VbEp6IRN"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVIoVtVQvbAX"
      },
      "outputs": [],
      "source": [
        "\n",
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sel977xkvbzA"
      },
      "outputs": [],
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5nJ-MOJvkPe"
      },
      "outputs": [],
      "source": [
        "train_ds[1]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3R-GviTFj1K"
      },
      "source": [
        "0: sadness (เศร้า)\n",
        "1: joy (ดีใจ/มีความสุข)\n",
        "2: love (รัก)\n",
        "3: anger (โกรธ)\n",
        "4: fear (กลัว)\n",
        "5: surprise (ประหลาดใจ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVRSWJskwoiQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(train_ds.features)\n",
        "\n",
        "print(train_ds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXfLY0lfxQw0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLoAlRfaxcdx"
      },
      "outputs": [],
      "source": [
        "def label_int2str(row):\n",
        "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxbpbP5txeAK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tg6Zhw-zIU4"
      },
      "outputs": [],
      "source": [
        "emotions.reset_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AFJuatZyOTJ"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8PrEkUMxiE5"
      },
      "outputs": [],
      "source": [
        "\n",
        "text = \"Tokenizing text is a core task of NLP.\"\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuLe2R8oxmte"
      },
      "outputs": [],
      "source": [
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
        "print(token2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JmF2nuXxtHt"
      },
      "outputs": [],
      "source": [
        "tokenized_text = text.split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9QF6Z32x8hI"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMhmQ8SYyD10"
      },
      "outputs": [],
      "source": [
        "print(tokenize(emotions[\"train\"][:2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFvD3-elpm9h"
      },
      "source": [
        "เติม Special Token  เพื่อ\n",
        "\n",
        "บอกโครงสร้างประโยค, ควบคุมพฤติกรรมการเรียนรู้ของโมเดล, ทำให้โมเดล ไม่เห็นเฉลยทั้งหมด ตอนเทรน โดย [unk] =unknown, [CLS] = token แรกของทุก sequence [SEP] = คั่นประโยค [Mask] = ซ่อยคำเพื่อไม่เห็นเฉลยทั้งหมด"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFMkUza3zScw"
      },
      "outputs": [],
      "source": [
        "#hide_input\n",
        "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
        "data = sorted(tokens2ids, key=lambda x : x[-1])\n",
        "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
        "df.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnrbXnAoqsmv"
      },
      "source": [
        "เข้ารหัส token ทั้งชุดข้อมูล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmzJrUNnzY-s"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQRpPjaMzg0A"
      },
      "outputs": [],
      "source": [
        "print(emotions_encoded[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Fo4OLYtpxc"
      },
      "source": [
        "attention_mask คือแผนที่บอกโมเดลว่า token ไหน มีตัวตนจริง  1 คือใช้ 0 คือไม่ใช้ กัน padding token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtqMlVbIq6vP"
      },
      "outputs": [],
      "source": [
        "emotions_encoded[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvvNo9TmssTa"
      },
      "source": [
        "โหลดโมเดล"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx-iTeUtzhxg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ikz78Susuds"
      },
      "source": [
        "ทดสอบดูขนาดของข้อมูล Tensor (batch,sequence_Length) ที่เป็น 6 เพราะเติม Token พิเศษ [CLS] this is a test [SEP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SECw9mxwz7FI"
      },
      "outputs": [],
      "source": [
        "\n",
        "text = \"this is a test\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")\n",
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5harqVjgvkcb"
      },
      "source": [
        "เอา input ผ่าน encoder ของโมเดลเรียบร้อยแล้ว และได้ vector ออกมา"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgWFYeMiz9ht"
      },
      "outputs": [],
      "source": [
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W07ab4a0eAd"
      },
      "outputs": [],
      "source": [
        "outputs.last_hidden_state.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhrb5Vgc0fKa"
      },
      "outputs": [],
      "source": [
        "\n",
        "outputs.last_hidden_state[:,0].size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzX_fHAPw_qP"
      },
      "source": [
        "ดึงค่า hidden state ของแต่ละประโยคออกมาแล้วใส่ใน json เดิมใช่ไหม ชื่อตัวแปรhidden state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbXjqvat0il9"
      },
      "outputs": [],
      "source": [
        "def extract_hidden_states(batch):\n",
        "    # Place model inputs on the GPU\n",
        "    inputs = {k:v.to(device) for k,v in batch.items()\n",
        "              if k in tokenizer.model_input_names}\n",
        "    # Extract last hidden states\n",
        "    with torch.no_grad():\n",
        "        last_hidden_state = model(**inputs).last_hidden_state\n",
        "    # Return vector for [CLS] token\n",
        "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iozu_GCT0nFL"
      },
      "outputs": [],
      "source": [
        "emotions_encoded.set_format(\"torch\",\n",
        "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pbFoNp8JSxi"
      },
      "source": [
        "เวกเตอร์ + UMAP + linear probe = การวัด representation ก่อน fine-tune เพื่อ วัดศักยภาพ representation แทนการ validate ตรง ๆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbdfEHYz0pBe"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HlpTgMi0qnv"
      },
      "outputs": [],
      "source": [
        "emotions_hidden[\"train\"].column_names\n",
        "print(emotions_hidden[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aF8bNCyyGyw"
      },
      "source": [
        "การทำ representation analysis + visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL0hTYso19pg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
        "X_train.shape, X_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imFPxzzzyWL4"
      },
      "source": [
        "ใช้ UMAP ในการลดมิติ hidden state แล้วพล็อตดูว่า class แต่ละอัน แยกกลุ่มกันได้ดีแค่ไหน X คือค่าแกนที่ 1 Y คือค่าแกนที่ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW1O7m1K2D8V"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale features to [0,1] range\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "# Initialize and fit UMAP\n",
        "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
        "# Create a DataFrame of 2D embeddings\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_emb[\"label\"] = y_train\n",
        "df_emb.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJHFJg6z0tS_"
      },
      "source": [
        "แผนที่การกระจายตัวของ sentence embeddings แยกตาม class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQeH_gZv2G6f"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "    df_emb_sub = df_emb.query(f\"label == {i}\")\n",
        "    axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap,\n",
        "                   gridsize=20, linewidths=(0,))\n",
        "    axes[i].set_title(label)\n",
        "    axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ4b2zb_1guR"
      },
      "source": [
        "ทำการเทรนตัวจำแนกประเภทเพื่อเรียนรู้ความสัมพันธ์ระหว่าง sentence embedding ของแต่ละประโยคกับคลาสอารมณ์ที่กำหนด"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlgrEkCU2Wyq"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "# We increase `max_iter` to guarantee convergence\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlgu0b5Q2Ojs"
      },
      "outputs": [],
      "source": [
        "\n",
        "lr_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdjAPwC12lqO"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM5AddfgFIps"
      },
      "source": [
        "จาก confusion matrix พบว่า เมื่อใช้ pretrained embedding ร่วมกับ Logistic Regression ผลลัพธ์ยังมีการสับสนระหว่างคลาสค่อนข้างมาก อย่างไรก็ตาม หลังจากทำการ fine-tuning โมเดล Transformer กับข้อมูลอารมณ์โดยตรง ความสามารถในการจำแนกคลาสดีขึ้นอย่างชัดเจน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0HQY5wN2qi6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "    plt.title(\"Normalized confusion matrix\")\n",
        "    plt.show()\n",
        "\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKiyJOtz33A0"
      },
      "source": [
        "ทำการ Fine-Tuned โมเดลด้วยข้อมูลดาต้าเซต"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtqck5aL3nfL"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 6\n",
        "model = (AutoModelForSequenceClassification\n",
        "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
        "         .to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9clkP2Kt3n6P"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAUjKVgY3tri"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4-j8xUh44gt"
      },
      "source": [
        "กำหนด parameter ที่ใช้ในการเทรน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxPw318F33Uv"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",      \n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=False,          \n",
        "    log_level=\"error\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSN4lsCh42e2"
      },
      "source": [
        "ทำการ Fine Tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCZADigD4EjB"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset=emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSXPhQsA5i6E"
      },
      "source": [
        "ทดสอบกับชุดข้อมูล Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llpd80XR4K6W"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "preds_output = trainer.predict(emotions_encoded[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWzTml2Z4OCw"
      },
      "outputs": [],
      "source": [
        "preds_output.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awPmYtze4SWK"
      },
      "outputs": [],
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By5WqzsS4S_B"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_preds, y_valid, labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UbKWQef6plo"
      },
      "source": [
        "ตรวจสอบผลลัพธ์รายประโยค  หลังการ fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKKM3sA14zGg"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_label(batch):\n",
        "    # Place all input tensors on the same device as the model\n",
        "    inputs = {k:v.to(device) for k,v in batch.items()\n",
        "              if k in tokenizer.model_input_names}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        pred_label = torch.argmax(output.logits, axis=-1)\n",
        "        loss = cross_entropy(output.logits, batch[\"label\"].to(device),\n",
        "                             reduction=\"none\")\n",
        "\n",
        "    # Place outputs on CPU for compatibility with other dataset columns\n",
        "    return {\"loss\": loss.cpu().numpy(),\n",
        "            \"predicted_label\": pred_label.cpu().numpy()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRp5h5Ho5ep4"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "# Convert our dataset back to PyTorch tensors\n",
        "emotions_encoded.set_format(\"torch\",\n",
        "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "# Compute loss values\n",
        "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(\n",
        "    forward_pass_with_label, batched=True, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbyCxz2R7QWm"
      },
      "source": [
        "เอาผลการทำนายรายประโยคหลัง fine-tuning มาอยู่ในรูป DataFrame เพื่อทำ error analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d79tGo7Z5kYI"
      },
      "outputs": [],
      "source": [
        "\n",
        "emotions_encoded.set_format(\"pandas\")\n",
        "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
        "df_test = emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\n",
        "df_test[\"predicted_label\"] = (df_test[\"predicted_label\"]\n",
        "                              .apply(label_int2str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCsnOFRL5lMB"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "df_test.sort_values(\"loss\", ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDOyqyvn5n-u"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "df_test.sort_values(\"loss\", ascending=True).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "errIi7Ts9qzu"
      },
      "source": [
        "Push Model ขึ้น Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wwOeYyO5uVS"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "trainer.push_to_hub(commit_message=\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU6JnoGD_acG"
      },
      "source": [
        "ทำการ Download โมเดลจาก  Hugging Face ที่ Deploy ไป"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfvOqgba5xLy"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "model_id = \"Posathip/distilbert-base-uncased-finetuned-emotion\"\n",
        "classifier = pipeline(\"text-classification\", model=model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFhhcwpm_mFu"
      },
      "source": [
        "ทดสอบผลลัพธ์ของประโยค"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpjAgxJG583z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "emotions = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
        "\n",
        "custom_tweet = \"I very enjoy in this class.\"\n",
        "preds = classifier(custom_tweet, return_all_scores=True)\n",
        "\n",
        "print(f\"Tweet: {custom_tweet}\")\n",
        "\n",
        "\n",
        "for i, pred in enumerate(preds[0]):\n",
        "    label_name = emotions[i]\n",
        "    print(f\"{label_name}: {pred['score']*100:.2f}%\")\n",
        "\n",
        "print(\"-\" * 20)\n",
        "\n",
        "\n",
        "preds_df = pd.DataFrame(preds[0])\n",
        "preds_df[\"label\"] = emotions\n",
        "\n",
        "plt.bar(preds_df[\"label\"], 100 * preds_df[\"score\"], color='C0')\n",
        "plt.title(f'\"{custom_tweet}\"')\n",
        "plt.ylabel(\"Class probability (%)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "objJ6tN26P4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhor1T-m6D6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
