{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jl4pgNu7ZHo"
      },
      "outputs": [],
      "source": [
        "# !pip install -U transformers[torch] datasets[audio] accelerate nltk sacrebleu rouge-score py7zr evaluate bertviz huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBPr3oWY7ZHq"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import pipeline, set_seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "214uL2wjLIQE"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Edb4su7ZHq"
      },
      "source": [
        "# Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVpgd0N97ZHr"
      },
      "source": [
        "## The CNN/DailyMail Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p90ovBV7ZHr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UyO6Uzk7ZHs"
      },
      "outputs": [],
      "source": [
        "sample = dataset[\"train\"][1]\n",
        "print(f\"\"\"\n",
        "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
        "\"\"\")\n",
        "print(sample[\"article\"][:500])\n",
        "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
        "print(sample[\"highlights\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8u1JONh7ZHs"
      },
      "source": [
        "## Text Summarization Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGpthNuA7ZHt"
      },
      "outputs": [],
      "source": [
        "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
        "\n",
        "summaries = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLjQUPwj7ZHt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "if 'nltk' in sys.modules:\n",
        "    del sys.modules['nltk']\n",
        "\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    print(f\"NLTK Version: {nltk.__version__}\")\n",
        "    nltk.download(\"punkt\")\n",
        "    nltk.download(\"punkt_tab\")\n",
        "    nltk.download(\"wordnet\")\n",
        "    from nltk.tokenize import sent_tokenize\n",
        "    print(\" NLTK พร้อมใช้งานแล้ว!\")\n",
        "except AttributeError:\n",
        "    print(\" ยังติดปัญหาเดิม ลองกด Runtime -> Restart session อีกครั้ง\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_-CyfYW7ZHt"
      },
      "outputs": [],
      "source": [
        "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
        "sent_tokenize(string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-xiPJu7ZHu"
      },
      "source": [
        "### Summarization Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulp6Qrlp7ZHu"
      },
      "outputs": [],
      "source": [
        "def three_sentence_summary(text):\n",
        "    return \"\\n\".join(sent_tokenize(text)[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aNih-F-7ZHu"
      },
      "outputs": [],
      "source": [
        "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omV9MedV7ZHu"
      },
      "source": [
        "### GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGuP8yUb7ZHu"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "from transformers import pipeline, set_seed\n",
        "\n",
        "set_seed(42)\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
        "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
        "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
        "summaries[\"gpt2\"] = \"\\n\".join(\n",
        "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPrqFg6YGMpT"
      },
      "outputs": [],
      "source": [
        "print(\"--- GROUND TRUTH (เฉลย) ---\")\n",
        "print(dataset[\"train\"][0][\"highlights\"])\n",
        "\n",
        "print(\"\\n--- GPT-2 GENERATED SUMMARY ---\")\n",
        "print(summaries[\"gpt2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuGxfwas7ZHu"
      },
      "source": [
        "### T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQu6bJ2o7ZHu"
      },
      "source": [
        "<img alt=\"T5\" width=\"700\" caption=\"Diagram of T5's text-to-text framework (courtesy of Colin Raffel); besides translation and summarization, the CoLA (linguistic acceptability) and STSB (semantic similarity) tasks are shown\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_t5.png?raw=1\" id=\"T5\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXwC8kMh7ZHv"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Z-aGuM7ZHv"
      },
      "source": [
        "### BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL1HItcD7ZHv"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECJZAn637ZHv"
      },
      "source": [
        "### PEGASUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr7ViV2R7ZHv"
      },
      "source": [
        "<img alt=\"pegasus\" width=\"700\" caption=\"Diagram of PEGASUS architecture (courtesy of Jingqing Zhang et al.)\" src=\"https://github.com/nlp-with-transformers/notebooks/blob/main/images/chapter08_pegasus.png?raw=1\" id=\"pegasus\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h8Y2HnA7ZHv"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM951w-VIwvg"
      },
      "outputs": [],
      "source": [
        "print(\"--- [GROUND TRUTH / เฉลย] ---\")\n",
        "print(dataset[\"train\"][1][\"highlights\"])\n",
        "\n",
        "print(\"\\n--- [GPT-2 SUMMARY] ---\")\n",
        "print(summaries.get(\"gpt2\", \"ยังไม่ได้รัน หรือรันไม่สำเร็จ\"))\n",
        "\n",
        "print(\"\\n--- [PEGASUS SUMMARY] ---\")\n",
        "print(summaries[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnUFjV7W7ZHv"
      },
      "source": [
        "## Comparing Different Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MdzsZm07ZHv"
      },
      "outputs": [],
      "source": [
        "print(\"GROUND TRUTH\")\n",
        "print(dataset[\"train\"][1][\"highlights\"])\n",
        "print(\"\")\n",
        "\n",
        "for model_name in summaries:\n",
        "    print(model_name.upper())\n",
        "    print(summaries[model_name])\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY1IN23R7ZHw"
      },
      "source": [
        "## Measuring the Quality of Generated Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plzu7vDR7ZHw"
      },
      "source": [
        "### BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9OpGUq57ZHw"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n",
        "# hide_output\n",
        "import evaluate\n",
        "\n",
        "# เปลี่ยนจาก load_metric เป็น evaluate.load\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSstyPlT7ZHw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "bleu_metric.add(\n",
        "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVvVePKp7ZHw"
      },
      "outputs": [],
      "source": [
        "bleu_metric.add(\n",
        "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poytNrAI7ZHx"
      },
      "source": [
        "### ROUGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcibbdXE7ZHx"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "import evaluate\n",
        "\n",
        "# เปลี่ยนจาก load_metric เป็น evaluate.load\n",
        "# 'rouge' ในไลบรารีใหม่จะคำนวณ ROUGE-1, ROUGE-2, ROUGE-L ให้ครบในตัวเดียว\n",
        "rouge_metric = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-y7vKjn7ZHx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "reference = dataset[\"train\"][8][\"highlights\"]\n",
        "records = []\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "for model_name in summaries:\n",
        "    # 1. ใส่ข้อมูลเข้า Metric\n",
        "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
        "\n",
        "    # 2. คำนวณคะแนน (เวอร์ชันใหม่คืนค่าเป็น dict ของ float เลย)\n",
        "    score = rouge_metric.compute()\n",
        "\n",
        "    # 3. ดึงค่าคะแนนออกมา (คูณ 100 เพื่อให้เป็นเปอร์เซ็นต์เหมือนในหนังสือ)\n",
        "    rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "    records.append(rouge_dict)\n",
        "\n",
        "# แสดงผลเป็น DataFrame\n",
        "pd.DataFrame.from_records(records, index=summaries.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4takkMIGCrCZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-sLdqbcF7va"
      },
      "outputs": [],
      "source": [
        "# ลองส่งข่าว 1 ชิ้นเข้าไปให้มันสรุปเลย\n",
        "sample_text = dataset[\"test\"][0][\"article\"]\n",
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\", device=0)\n",
        "print(pipe(sample_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroGJyHB7ZHx"
      },
      "source": [
        "## Evaluating PEGASUS on the CNN/DailyMail Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZulkmF67ZHx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import evaluate  # เปลี่ยนจาก load_metric เป็น evaluate\n",
        "\n",
        "# 1. โหลด Dataset (ระบุชื่อโครงสร้างข้อมูล \"3.0.0\" เป็นพารามิเตอร์ที่สอง)\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "# 2. โหลด Metric ผ่าน Library evaluate\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# 3. กำหนดชื่อ ROUGE สำหรับใช้ในตอนแสดงผล\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "print(\"Setup Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB-KAWIx7ZHx"
      },
      "outputs": [],
      "source": [
        "def evaluate_summaries_baseline(dataset, metric,\n",
        "                                column_text=\"article\",\n",
        "                                column_summary=\"highlights\"):\n",
        "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "    metric.add_batch(predictions=summaries,\n",
        "                     references=dataset[column_summary])\n",
        "    score = metric.compute()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MlNEGd_7ZHy"
      },
      "outputs": [],
      "source": [
        "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# คำนวณคะแนน (ตรวจสอบให้แน่ใจว่าฟังก์ชัน evaluate_summaries_baseline ใช้ rouge_metric.compute() แล้ว)\n",
        "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
        "\n",
        "# ดึงคะแนนออกมาแบบตรงๆ คูณ 100\n",
        "rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "\n",
        "# สร้าง DF แสดงผล\n",
        "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyASwlOo7ZHy"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def chunks(list_of_elements, batch_size):\n",
        "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"article\",\n",
        "                               column_summary=\"highlights\"):\n",
        "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        # ใช้ inference_mode เพื่อความเร็วและประหยัดแรม\n",
        "        with torch.inference_mode():\n",
        "            summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                             attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                             length_penalty=0.8, num_beams=2, max_length=64)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    # ตรงนี้สำคัญ: evaluate คืนค่าเป็น dict ของ float ทันที\n",
        "    score = metric.compute()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q22dp3mB7ZH2"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
        "                                   model, tokenizer, batch_size=2)\n",
        "rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2iy3LM37ZH2"
      },
      "outputs": [],
      "source": [
        "# hide_input\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x14OVhplHJ75"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # สุ่มตรวจความยาวจากชุด train\n",
        "# test_sample = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# d_len = [len(tokenizer.encode(s)) for s in test_sample[\"article\"]]\n",
        "# s_len = [len(tokenizer.encode(s)) for s in test_sample[\"highlights\"]]\n",
        "\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
        "# axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
        "# axes[0].set_title(\"Article Token Length\")\n",
        "# axes[0].set_xlabel(\"Length\")\n",
        "# axes[0].set_ylabel(\"Count\")\n",
        "# axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
        "# axes[1].set_title(\"Highlights Token Length\")\n",
        "# axes[1].set_xlabel(\"Length\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD1EpByRKxng"
      },
      "outputs": [],
      "source": [
        "# # เลือก Subset เพื่อประหยัดเวลา (ถ้าจะเอาทั้งหมดยกออกได้ครับ)\n",
        "# train_subset = dataset[\"train\"].shuffle(seed=42).select(range(500))\n",
        "# val_subset = dataset[\"validation\"].shuffle(seed=42).select(range(100))\n",
        "\n",
        "# def convert_examples_to_features(example_batch):\n",
        "#     # เปลี่ยน dialogue เป็น article\n",
        "#     input_encodings = tokenizer(example_batch[\"article\"], max_length=1024,\n",
        "#                                 truncation=True)\n",
        "\n",
        "#     with tokenizer.as_target_tokenizer():\n",
        "#         # เปลี่ยน summary เป็น highlights\n",
        "#         target_encodings = tokenizer(example_batch[\"highlights\"], max_length=128,\n",
        "#                                      truncation=True)\n",
        "\n",
        "#     return {\"input_ids\": input_encodings[\"input_ids\"],\n",
        "#             \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "#             \"labels\": target_encodings[\"input_ids\"]}\n",
        "\n",
        "# dataset_cnn_pt = train_subset.map(convert_examples_to_features, batched=True)\n",
        "# dataset_cnn_val_pt = val_subset.map(convert_examples_to_features, batched=True)\n",
        "\n",
        "# columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "# dataset_cnn_pt.set_format(type=\"torch\", columns=columns)\n",
        "# dataset_cnn_val_pt.set_format(type=\"torch\", columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qm7RDeDK2R3"
      },
      "outputs": [],
      "source": [
        "# from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "\n",
        "# seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir='pegasus-cnn-finetuned',\n",
        "#     num_train_epochs=1,\n",
        "#     warmup_steps=100,             # ลดลงให้เหมาะกับ Subset\n",
        "#     per_device_train_batch_size=1,\n",
        "#     per_device_eval_batch_size=1,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_steps=10,\n",
        "#     push_to_hub=True,\n",
        "#     eval_strategy='steps',\n",
        "#     eval_steps=100,               # ประเมินผลทุกๆ 100 steps\n",
        "#     save_steps=1e6,\n",
        "#     gradient_accumulation_steps=16,\n",
        "#     fp16=True\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(model=model, args=training_args,\n",
        "#                   tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "#                   train_dataset=dataset_cnn_pt,\n",
        "#                   eval_dataset=dataset_cnn_val_pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OamTIPUHKYr"
      },
      "outputs": [],
      "source": [
        "# # เริ่มเทรน\n",
        "# trainer.train()\n",
        "\n",
        "# # วัดผลด้วย ROUGE (ใช้ชุด test ของ cnn)\n",
        "# test_subset = dataset[\"test\"].shuffle(seed=42).select(range(100))\n",
        "# score = evaluate_summaries_pegasus(\n",
        "#     test_subset, rouge_metric, trainer.model, tokenizer,\n",
        "#     batch_size=2, column_text=\"article\", column_summary=\"highlights\")\n",
        "\n",
        "# rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "# pd.DataFrame(rouge_dict, index=[\"pegasus (fine-tuned-cnn)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXnX0J4Ldgr"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE4uc7wXHinq"
      },
      "outputs": [],
      "source": [
        "# # ทดสอบใช้งานด้วย Pipeline\n",
        "# from transformers import pipeline\n",
        "# gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\": 128}\n",
        "\n",
        "# # เปลี่ยน URL เป็น username ของคุณ\n",
        "# pipe = pipeline(\"summarization\", model=\"Posathip/pegasus-cnn-finetuned\")\n",
        "\n",
        "# sample_article = dataset[\"test\"][0][\"article\"]\n",
        "# print(\"Article:\")\n",
        "# print(sample_article[:500] + \"...\")\n",
        "# print(\"\\nModel Summary:\")\n",
        "# print(pipe(sample_article, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIiqsf-LHyaO"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrKGoU0lHjoQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZsVveHlJVXg"
      },
      "outputs": [],
      "source": [
        "# # ส่งขึ้น Hub\n",
        "# trainer.push_to_hub(\"Finetuned Pegasus on CNN subset by [ใส่ชื่อคุณ]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byOT7Osa7ZH2"
      },
      "source": [
        "## Training a Summarization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH79jDfZ7ZH2"
      },
      "outputs": [],
      "source": [
        "# แก้บรรทัดนี้ครับ\n",
        "dataset_samsum = load_dataset(\"knkarthick/dialogsum\")\n",
        "\n",
        "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
        "\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
        "print(\"\\nDialogue:\")\n",
        "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(dataset_samsum[\"test\"][0][\"summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M01wzCN37ZH3"
      },
      "outputs": [],
      "source": [
        "# hide_input\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
        "print(\"\\nDialogue:\")\n",
        "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(dataset_samsum[\"test\"][0][\"summary\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10t_SWGq7ZH3"
      },
      "source": [
        "### Evaluating PEGASUS on SAMSum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxO-lna17ZH3"
      },
      "outputs": [],
      "source": [
        "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
        "print(\"Summary:\")\n",
        "print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmRWjmH17ZH3"
      },
      "outputs": [],
      "source": [
        "\n",
        "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
        "                                   tokenizer, column_text=\"dialogue\",\n",
        "                                   column_summary=\"summary\", batch_size=8)\n",
        "\n",
        "\n",
        "rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "\n",
        "# แสดงผลเป็นตารางสวยๆ\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNiFAfXu7ZH3"
      },
      "outputs": [],
      "source": [
        "# hide_input\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9anHnsUB7ZH4"
      },
      "source": [
        "### Fine-Tuning PEGASUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbGyOEDF7ZH4"
      },
      "outputs": [],
      "source": [
        "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
        "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
        "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
        "axes[0].set_title(\"Dialogue Token Length\")\n",
        "axes[0].set_xlabel(\"Length\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
        "axes[1].set_title(\"Summary Token Length\")\n",
        "axes[1].set_xlabel(\"Length\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlTCAhmq7ZH4"
      },
      "outputs": [],
      "source": [
        "#hide_output\n",
        "def convert_examples_to_features(example_batch):\n",
        "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n",
        "                                truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n",
        "                                     truncation=True)\n",
        "\n",
        "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
        "            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "            \"labels\": target_encodings[\"input_ids\"]}\n",
        "\n",
        "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
        "                                       batched=True)\n",
        "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsnKdIeU7ZH4"
      },
      "outputs": [],
      "source": [
        "#hide_input\n",
        "\n",
        "#id teacher-forcing\n",
        "#alt Decoder input and label alignemt for text generation.\n",
        "#caption Decoder input and label alignemt for text generation.\n",
        "text = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\n",
        "rows = []\n",
        "for i in range(len(text)-1):\n",
        "    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\n",
        "pd.DataFrame(rows).set_index('step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFv2sGtF7ZH4"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUow2BO47ZH5"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum',\n",
        "    num_train_epochs=1,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    push_to_hub=True,\n",
        "    eval_strategy='steps',    \n",
        "    eval_steps=500,\n",
        "    save_steps=1e6,\n",
        "    gradient_accumulation_steps=16,\n",
        "    fp16=True               \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wzJTSjP7ZH5"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKIi1VIf7ZH5"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4xkLHw77ZH5"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "\n",
        "score = evaluate_summaries_pegasus(\n",
        "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
        "    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "\n",
        "\n",
        "# ใช้ Dictionary Comprehension เพื่อดึงค่ามาคูณ 100 ให้ดูง่ายขึ้น\n",
        "rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "\n",
        "# 3. แสดงผลเป็นตาราง\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LTFe52CKXdZ"
      },
      "outputs": [],
      "source": [
        "rouge_dict = {rn: score[rn] * 100 for rn in rouge_names}\n",
        "\n",
        "# แสดงผลเป็นตารางสวยๆ\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(rouge_dict, index=[\"pegasus (fine-tuned)\"])\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1rgzVm-7ZH5"
      },
      "outputs": [],
      "source": [
        "# hide_input\n",
        "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQngBlVo7ZH5"
      },
      "outputs": [],
      "source": [
        "# hide_output\n",
        "trainer.push_to_hub(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXCZrZPL7ZH6"
      },
      "source": [
        "### Generating Dialogue Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1OJ6dQ57ZH6"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgeUfdmu7ZH6"
      },
      "outputs": [],
      "source": [
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
        "sample_text = dataset_samsum[\"test\"][1][\"dialogue\"]\n",
        "reference = dataset_samsum[\"test\"][1][\"summary\"]\n",
        "pipe = pipeline(\"summarization\", model=\"Posathip/pegasus-samsum\")\n",
        "\n",
        "print(\"Dialogue:\")\n",
        "print(sample_text)\n",
        "print(\"\\nReference Summary:\")\n",
        "print(reference)\n",
        "print(\"\\nModel Summary:\")\n",
        "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCV5CiDG7ZH6"
      },
      "outputs": [],
      "source": [
        "custom_dialogue = \"\"\"\\\n",
        "Thom: Hi guys, have you heard of transformers?\n",
        "Lewis: Yes, I used them recently!\n",
        "Leandro: Indeed, there is a great library by Hugging Face.\n",
        "Thom: I know, I helped build it ;)\n",
        "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
        "Leandro: Great idea, how hard can it be?!\n",
        "Thom: I am in!\n",
        "Lewis: Awesome, let's do it together!\n",
        "\"\"\"\n",
        "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu6atUNS7ZH6"
      },
      "source": [
        "## Conclusion"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
